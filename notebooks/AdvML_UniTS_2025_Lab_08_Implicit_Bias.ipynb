{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 8: **Implicit bias** of gradient descent: the case of *linear regression*\n",
                "\n",
                "Advanced Topics in Machine Learning -- Fall 2025, UniTS\n",
                "\n",
                "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ganselmif/adv-ml-units/blob/main/notebooks/AdvML_UniTS_2025_Lab_08_Implicit_Bias.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Overview of the *Lab*\n",
                "\n",
                "In this lab, we will study the *implicit bias* induced by *Gradient Descent* optimization in the simple case of *linear regression*, fitted on a *toy* dataset. In particular, we will show that *GD*-optimized weights converge to the **least norm** solution of the *linear regression* problem.\n",
                "\n",
                "An analysis of implicit bias induced by *Stochastic Gradient Descent* in *full-width linear fully-connected* and *full-width linear convolutional* neural networks (which are much more complex and expressive models!) is provided in [this paper](https://arxiv.org/abs/1806.00468).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Linear regression\n",
                "\n",
                "In the case of **linear regression**, fitted by means of *least squares*, we optimize the following loss function:\n",
                "$$\n",
                "L=\\|y-Xw\\|_{2}^{2}\n",
                "$$.\n",
                "\n",
                "If we choose the *GD* optimization algorithm, we perform weight updates proportional to the gradient of the loss function:\n",
                "$$\n",
                "\\nabla_{w} L = -X(y-Xw)\n",
                "$$.\n",
                "\n",
                "Additionally, notice that the **least norm** solution of the *linear regression* problem is given by:\n",
                "$$\n",
                "w^{*}=(X^{T}X)^{-1}X^{T}y\n",
                "$$.\n"
            ],
            "metadata": {
                "collapsed": false
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "source": [
                "import numpy as np"
            ],
            "metadata": {
                "collapsed": false
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### To-do:\n",
                "\n",
                "The following *toy* dataset is provided:"
            ],
            "metadata": {
                "collapsed": false
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "source": [
                "m, n = 1000, 10\n",
                "X = np.random.normal(0, 1, (m, n))\n",
                "b = X.dot(np.random.normal(0, 1, n))"
            ],
            "metadata": {
                "collapsed": false
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "1. Compute the *least norm* solution of the linear regression problem;\n",
                "2. Write a function that computes the gradient of the loss function, as required by *GD* optimization;\n",
                "3. Perform *GD* optimization of the linear regression problem iteratively, storing the weights at each iteration;\n",
                "4. Plot the evolution of the weights during *GD* optimization and comment.\n"
            ],
            "metadata": {
                "collapsed": false
            }
        }
    ],
    "metadata": {
        "colab": {
            "authorship_tag": "ABX9TyPkibvpTEMRILBn2/x8IuJj",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
